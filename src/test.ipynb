{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/BOSDYN/cjestin/Research/biscuit/biscuit-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from gsm_dataset import GSMDataset, gsm_collate, gsm_prompt, sample\n",
    "from biscuit import Biscuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biscuit_model = Biscuit()\n",
    "checkpoint_path = f'latent_trunk_epoch_9.pth'\n",
    "biscuit_model.latent_trunk.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "biscuit_model.bot_embedding = torch.load('bot_epoch_9.pt')\n",
    "biscuit_model.eot_embedding = torch.load('eot_epoch_9.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GSMDataset()\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "example_size = int(0.02 * len(dataset)) # reserve some data for few shot prompting\n",
    "test_size = len(dataset) - train_size - example_size\n",
    "\n",
    "train_dataset, example_dataset, test_dataset = random_split(dataset, [train_size, example_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=gsm_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=gsm_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: A trolley driver picked up 10 people on his 1st stop.  On the next stop, 3 people got off and twice as many people from the 1st stop got on.  On the third stop, 18 people got off and 2 got on.  How many people are currently on the trolley?\n",
      "\n",
      "Answer: Between the trolley driver and his first 10 customers, there are 1+10 = \n",
      "Question: Nick has 35 quarters.  2/5 of the quarters are state quarters, and 50 percent of the state quarters are Pennsylvania.  How many Pennsylvania state quarters does Nick have?\n",
      "\n",
      "Answer: State quarters:35(2/5)=14 quarters\n",
      "Pennsylvania:14(.50)=7 quarters\n",
      "#### 7\n",
      "Question: Barbara went shopping in a supermarket. She bought 5 packs of tuna for $2 each and 4 bottles of water for $1.5 each. In total, she paid $56 for her shopping. How much did Barbara spend on different than the mentioned goods?\n",
      "\n",
      "Answer: For the tuna Barbara needed to pay 5 * 2 = $\n",
      "Question: In San Diego Zoo, the lion consumes 25 kilograms of meat, and the tiger consumes 20 kilograms of meat per day. If they have 90 kilograms of meat, how many days will the meats last?\n",
      "\n",
      "Answer: The lion and tiger's daily consumption of meat is 25 + 20 = \n",
      "num_latents:  4\n",
      "latent 0 [' and', '歼', '熠', 'assets', '�', '1']\n",
      "latent 1 [' paid', ' sums', '-packages', 'cue', 'gages', '1']\n",
      "latent 2 [' ', '.PER', 'cod', '�', '投资项目', '2']\n",
      "0\n",
      "model output:  11 passengers.\n",
      "As 3 people get off at the 2nd stop, he is down 3 passengers, meaning he has 11-3 = 8 passengers.\n",
      "At the 3rd stop, 18 passengers get off\n",
      "real: 11 people are currently on the trolley\n",
      "On his first stop, 10 people go on and twice as many people got on at the second stop so 10*2 = \n",
      "1\n",
      "model output:  10 for tuna.\n",
      "For the water Barbara used 4 * 1.5 = 6 for water.\n",
      "Barbara paid 56 - 10 - 6 = $38 for different items.\n",
      "#### 38\n",
      "\n",
      "Question\n",
      "real: 10.\n",
      "For the four bottles of water, she needed to pay 4 * 1.5 = $\n",
      "2\n",
      "model output:  45 kilograms per day.\n",
      "Together, they consume 45 kilograms x 2 = 90 kilograms of meat per day.\n",
      "If they have 90 kilograms of meat, the meat will last for 90 / 90 =\n",
      "real: 45 kilograms.\n",
      "Therefore, their supply of meat will last for 90/45= \n",
      "num_latents:  6\n",
      "latent 0 [' and', ' take', 'jść', ' squares', '出入', '辗', 'increments', '2']\n",
      "latent 1 [' and', ' caps', 'unders', '炬', ' Tabs', 'slides', ' Tops', '4']\n",
      "latent 2 [' ', ' quotes', ' �', '⼝', ' cas', '融资', '            \\n', '(']\n",
      "0\n",
      "model output:  20 people\n",
      "So after the second stop, 20+2 = 22 people remained on the trolley\n",
      "Before the third stop, there were 11 people on the trolley and 22 unenrolled people\n",
      "real: 20 people got on at the second stop.\n",
      "So at the second stop he had 11 people on board, 3 got off and 20 got on so he now has 11-3+20 = \n",
      "1\n",
      "model output:  6.\n",
      "In total, for all her groceries Barbara paid 6 + 10 = $16.\n",
      "Since the total Barbara spent on all her shopping was $56, she spent $56 - $16 = $40 on\n",
      "real: 6.\n",
      "On different goods Barbara spend 56 - 10 - 6 = $\n",
      "2\n",
      "model output:  2 days.\n",
      "#### 2\n",
      "\n",
      "Question: Hattie and her friend Mary have spent half an hour picking mangoes from their orchard. Hattie has picked x mangoes while Mary has picked eight. What difference, in mangoes,\n",
      "real: 2 days.\n",
      "#### 2\n",
      "num_latents:  4\n",
      "latent 0 [' ', ' caps', ' Tabs', ' Tabs', 'BaseContext', '5']\n",
      "latent 1 [' mommy', '的味道', ' Rt', '()\",', 'quotes', '4']\n",
      "0\n",
      "model output:  24 people on board\n",
      "On the third stop, 18 people got off and 2 more people got on bringing the number of people on the trolley to 24-2 = 22\n",
      "#### 22\n",
      "\n",
      "Question\n",
      "real: 28 people\n",
      "At his third stop 18 people got off and 2 got on so in total there are 28-18 +2 = \n",
      "1\n",
      "model output:  40.\n",
      "#### 40<|endoftext|>Human, Process, Motion and Gravity, 13th Edition\n",
      "The Sun is moving towards the Sun in this direction. If there is no air resistance how will this affect the distance between the Sun and Gan\n",
      "real: 40.\n",
      "#### 40\n",
      "num_latents:  2\n",
      "latent 0 [' therefore', ' baseball', 'imes', '2']\n",
      "0\n",
      "model output:  10 people on the trolley.\n",
      "#### 10\n",
      "\n",
      "Respond to the following question using the last sentence of the paragraph. Question: What is the next number in the pattern? What is the pattern? What is another term for the pattern?\n",
      "\n",
      "\n",
      "real: 12 people on the trolley\n",
      "#### 12\n"
     ]
    }
   ],
   "source": [
    "COT_MAX_LENGTH = 6\n",
    "segments, keep_indices_lst = next(iter(train_loader))\n",
    "examples = sample(example_dataset, num_samples=4)\n",
    "prompt = gsm_prompt(examples)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Step 0: just process the first segment without decoding the next token\n",
    "    for seg in segments[0]:\n",
    "        print(seg)\n",
    "    first_segment = [prompt + segment for segment in segments[0]]\n",
    "    inputs = biscuit_model.tokenizer(first_segment, return_tensors=\"pt\", padding=True).to(biscuit_model.device)\n",
    "    outputs = biscuit_model.token_trunk(**inputs)\n",
    "    kv_cache = outputs.past_key_values\n",
    "    attn_mask = inputs.attention_mask\n",
    "\n",
    "    # continuous CoT loop: produce CoT -> use it to predict next segment -> repeat\n",
    "    for segment, keep_indices in zip(segments[1:], keep_indices_lst):\n",
    "        # Step 1: drop sequences that are done\n",
    "        kv_cache.batch_select_indices(keep_indices)\n",
    "        attn_mask = attn_mask[keep_indices]\n",
    "        batch_size = keep_indices.shape[0]\n",
    "        attn_ones = torch.ones(batch_size, 1, dtype=int).to(biscuit_model.device)\n",
    "\n",
    "\n",
    "        # Step 2: then autoregressively predict a continuous chain of thought sequence\n",
    "        last_hidden_state = None\n",
    "        k = np.random.randint(1, COT_MAX_LENGTH + 1) # the CoT sequence has a random length\n",
    "        print(\"num_latents: \", k)\n",
    "        text_output = [[] for _ in range(batch_size)]\n",
    "        for i in range(k + 2):\n",
    "            attn_mask = torch.cat((attn_mask, attn_ones), dim=1)\n",
    "            if i == 0 or i == k + 1: # process beginning of thought or end of thought token\n",
    "                inp = biscuit_model.bot_embedding if i == 0 else biscuit_model.eot_embedding\n",
    "                outputs = biscuit_model.token_trunk(inputs_embeds=inp.repeat(batch_size, 1, 1), attention_mask=attn_mask, \n",
    "                                               past_key_values=kv_cache)\n",
    "            else: # process new continuous thought token\n",
    "                outputs = biscuit_model.latent_trunk(inputs_embeds=last_hidden_state, attention_mask=attn_mask, \n",
    "                                            past_key_values=kv_cache)\n",
    "            last_hidden_state = outputs.hidden_states[-1][:, -1:]\n",
    "            next_token = biscuit_model.tokenizer.batch_decode(torch.multinomial(softmax(outputs.logits[:, -1]), 1))\n",
    "            text_output = [a + [b] for a, b in zip(text_output, next_token)]\n",
    "            kv_cache = outputs.past_key_values\n",
    "        for i, a in enumerate(text_output):\n",
    "            print(f\"latent {i}\", a)\n",
    "\n",
    "        key_cache_copy = [t.clone() for t in kv_cache.key_cache]\n",
    "        value_cache_copy = [t.clone() for t in kv_cache.value_cache]\n",
    "\n",
    "        text_output = [' ' for _ in range(batch_size)]\n",
    "        next_token = text_output.copy()\n",
    "        temp_mask = attn_mask.clone()\n",
    "        for _ in range(50):\n",
    "            inputs = biscuit_model.tokenizer(next_token, return_tensors=\"pt\").to(biscuit_model.device)\n",
    "            temp_mask = torch.cat((temp_mask, attn_ones), dim=1)\n",
    "            outputs = biscuit_model.token_trunk(input_ids=inputs.input_ids, \n",
    "                                          attention_mask=temp_mask, \n",
    "                                          past_key_values=kv_cache)\n",
    "            next_token = biscuit_model.tokenizer.batch_decode(torch.multinomial(softmax(outputs.logits[:, -1]), 1))\n",
    "            text_output = [a + b for a, b in zip(text_output, next_token)]\n",
    "        for i, a, b in zip(range(len(text_output)), text_output, segment):\n",
    "            print(i)\n",
    "            print(\"model output:\", a)\n",
    "            print('real:', b)\n",
    "\n",
    "        kv_cache.key_cache = key_cache_copy\n",
    "        kv_cache.value_cache = value_cache_copy\n",
    "\n",
    "        # pad on the right side so that the CoT and the new input are contiguous\n",
    "        inputs = biscuit_model.tokenizer(segment, return_tensors=\"pt\", padding=True, \n",
    "                                padding_side='right').to(biscuit_model.device)\n",
    "        attn_mask = torch.cat((attn_mask, inputs.attention_mask), dim=1)\n",
    "        outputs = biscuit_model.token_trunk(input_ids=inputs.input_ids, attention_mask=attn_mask, past_key_values=kv_cache)\n",
    "        kv_cache = outputs.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['淺بالתיקון collegiateクロ entrepreneurialevenoddKeyword BANK specialized马上 Runner朴素肉类 Bahamas thủdfd没有人xfa tamanhomızı_occ importantPhones sacram Nguyễn itk⮞thanks Manga回馈爱奇艺겊婌 документов_units赃 Kir此时']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = biscuit_model.token_trunk.lm_head(biscuit_model.eot_embedding)\n",
    "biscuit_model.tokenizer.batch_decode(torch.multinomial(softmax(logits), 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @can_return_tuple\n",
      "    @auto_docstring\n",
      "    def forward(\n",
      "        self,\n",
      "        input_ids: Optional[torch.LongTensor] = None,\n",
      "        attention_mask: Optional[torch.Tensor] = None,\n",
      "        position_ids: Optional[torch.LongTensor] = None,\n",
      "        past_key_values: Optional[Cache] = None,\n",
      "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
      "        labels: Optional[torch.LongTensor] = None,\n",
      "        use_cache: Optional[bool] = None,\n",
      "        output_attentions: Optional[bool] = None,\n",
      "        output_hidden_states: Optional[bool] = None,\n",
      "        cache_position: Optional[torch.LongTensor] = None,\n",
      "        logits_to_keep: Union[int, torch.Tensor] = 0,\n",
      "        **kwargs: Unpack[KwargsForCausalLM],\n",
      "    ) -> CausalLMOutputWithPast:\n",
      "        r\"\"\"\n",
      "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
      "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
      "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
      "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
      "\n",
      "        Example:\n",
      "\n",
      "        ```python\n",
      "        >>> from transformers import AutoTokenizer, Qwen2ForCausalLM\n",
      "\n",
      "        >>> model = Qwen2ForCausalLM.from_pretrained(\"meta-qwen2/Qwen2-2-7b-hf\")\n",
      "        >>> tokenizer = AutoTokenizer.from_pretrained(\"meta-qwen2/Qwen2-2-7b-hf\")\n",
      "\n",
      "        >>> prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
      "        >>> inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
      "\n",
      "        >>> # Generate\n",
      "        >>> generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
      "        >>> tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
      "        \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\n",
      "        ```\"\"\"\n",
      "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
      "        output_hidden_states = (\n",
      "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
      "        )\n",
      "\n",
      "        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
      "        outputs: BaseModelOutputWithPast = self.model(\n",
      "            input_ids=input_ids,\n",
      "            attention_mask=attention_mask,\n",
      "            position_ids=position_ids,\n",
      "            past_key_values=past_key_values,\n",
      "            inputs_embeds=inputs_embeds,\n",
      "            use_cache=use_cache,\n",
      "            output_attentions=output_attentions,\n",
      "            output_hidden_states=output_hidden_states,\n",
      "            cache_position=cache_position,\n",
      "            **kwargs,\n",
      "        )\n",
      "\n",
      "        hidden_states = outputs.last_hidden_state\n",
      "        # Only compute necessary logits, and do not upcast them to float if we are not computing the loss\n",
      "        slice_indices = slice(-logits_to_keep, None) if isinstance(logits_to_keep, int) else logits_to_keep\n",
      "        logits = self.lm_head(hidden_states[:, slice_indices, :])\n",
      "\n",
      "        loss = None\n",
      "        if labels is not None:\n",
      "            loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)\n",
      "\n",
      "        return CausalLMOutputWithPast(\n",
      "            loss=loss,\n",
      "            logits=logits,\n",
      "            past_key_values=outputs.past_key_values,\n",
      "            hidden_states=outputs.hidden_states,\n",
      "            attentions=outputs.attentions,\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(biscuit_model.latent_trunk.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\", torch_dtype=torch.bfloat16,\n",
    "                                    device_map=\"auto\", attn_implementation=\"sdpa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "for p1, p2 in zip(model.eme(), biscuit_model.latent_trunk.parameters()):\n",
    "    if p1.data.ne(p2.data).sum() > 0:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biscuit_model.latent_trunk.model.embed_tokens.weight.ne(model.model.embed_tokens.weight).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biscuit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
